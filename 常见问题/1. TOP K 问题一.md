## 1. TOP K大的数

### 描述

在海量数据中，找到TOP k大的数



### 解法一：堆排序（小顶堆）

#### 步骤

1. 建堆

   建立一个大小为 K 的小顶堆，依次将数据放入堆中，方

2. 依次插入堆

   当堆的大小满了的时候，只需要将堆顶元素与下一个数比较：如果大于堆顶元素，**就替换该堆顶，然后做堆调整。**

遍历完全部数据，Top K 的元素也自然都在堆里面了。



#### 分析

该方法的**时间复杂度是 O(nlog K)** 

遍历数组需要 O(n) 的时间复杂度，一次堆化操作需要 O(logK)，加起来就是**O(nlog K)**的复杂度

换个角度来看，如果 K 远小于 n 的话， O(nlogK) 其实就接近于 **O(n)** 了，甚至会更快，因此也是十分高效的。



### 解法二：剪枝的快排

#### 步骤

如果每次经过划分，如果中间值等于 K ，那么其左边的数就是 Top K 的数据；

如果不等于，只要递归处理左边或者右边的数即可



#### 分析

该方法的**时间复杂度是 O(n)** 

简单分析就是第一次划分时遍历数组需要花费 n，而往后每一次都折半（当然不是准确地折半）

粗略地计算就是 n + n/2 + n/4 +... < 2n，因此显然时间复杂度是 O(n)



## 2. 重复次数最多的n个串

### 2.1Hash+堆排序

采用Hash+小顶堆
Hash就是为了统计每个数出现的次数，然后发生冲突的地方用个链表把它链接起来，在每个节点中存储一个含有**data和count成员的结构体**，data记录相应的数字，而count记录对应的数字出现的次数，这一步的时间复杂度是o(n).（注意这里虽然数字很多，但是因为会存在大量的重复数据，不用担心最后的空间会有10亿）,然后创建一个大小为100的小顶堆，然后将Hash表中前面100个非空的成员放入小顶堆中，然后将hash表中的其他数据和堆顶出现的次数比较，如果比堆顶出现的次数少，则丢弃当前数，如果大于堆顶元素的出现次数，则替换堆顶，然后进行堆调整，这一步时间复杂度是o(nlog100).
  总的时间复杂度是o(n)+o(nlog100)

### 2.2 Hash+桶排序（桶是一个小文件）

  1、首先预设1024个文件作为“桶”，依次读取原始数据的记录，每读到一条记录就进行哈希计算
  2、由于相同的记录哈希值一定相同，所以重复数据一定落入同一个桶内，对于落入同一个桶内的数据，直接为该数据的数量加一，即桶内的条目都是唯一的，各自记录自己的总重复数量。
  3、当一个桶的体积达到64M的时候（应该非常罕见），为该桶增加一个子桶，新的数据进来的时候先在父桶内找相同记录，没有的话在放入子桶，重复数设置为1。
  4、当全部数据读取完之后，依次对1024个桶（及其子桶）进行内部排序，可以一次性把64M的数据读入内存快速排序即可，然后再归并父桶及其子桶，最终得到1024个已经内部排序的桶。
  5、最后，构造一个容量为100的大堆，遍历1024个桶，每次从桶内取出一个数放进堆中，如果堆中没有数字被替换出来，则换到下一个桶继续取数字放进堆中，如果堆中的数字被换出来一个，则继续从该桶取数据。直到连续1024次替换没有新的数子桶堆中被换出来位置。
  6、最后得到的100容量的大堆即为所求。



总的来说：

1. HASH放入1024个桶
2. 每个桶内部排序
3. 1024个桶归并排序，归并n个就行



## 3.两个大文件的交集

要细分场景

### 3.1 文件里存的是任意字符串

方法：

1. 分治，分成多个小文件
2. 两个小文件求交集

分治法：根据文件大小以及内存情况，分为k个小文件，总共2k个小文件

依次把两个小文件读入内存，进行求交集。（具体怎么求，可以用hashmap）

